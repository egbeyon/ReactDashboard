from flask import Flask, jsonify, request
from pymongo import MongoClient
import yfinance as yf
from sec_api import QueryApi
import pandas as pd
import datetime

app = Flask(__name__)

# MongoDB Configuration (Environment Variables for Production)
MONGO_URI = os.environ.get("MONGO_URI") # Get URI from Environment Variable
client = MongoClient(MONGO_URI)
db = client["stock_analysis"]  # Database name
collection = db["filings"] # Collection name

# SEC API Configuration (Environment Variables for Production)
SEC_API_KEY = os.environ.get("SEC_API_KEY") # Get API Key from Environment Variable
query_api = QueryApi(api_key=SEC_API_KEY)


def get_filings_data(ticker):
    try:
        search_10k = f'ticker:{ticker} AND formType:"10-K" AND filedAt:[2019-01-01 TO 2024-12-31]'
        search_10q = f'ticker:{ticker} AND formType:"10-Q" AND filedAt:[2019-01-01 TO 2024-12-31]'
        res_10k = {"query": search_10k, "from": "0"}
        res_10q = {"query": search_10q, "from": "0"}
        response_10k = query_api.get_filings(res_10k)
        response_10q = query_api.get_filings(res_10q)
        filings_10k = pd.DataFrame(response_10k.get("filings", [])) # Handle potential missing 'filings'
        filings_10q = pd.DataFrame(response_10q.get("filings", [])) # Handle potential missing 'filings'
        filings = pd.concat([filings_10k, filings_10q], ignore_index=True)

        if filings.empty:
          return None

        filings['filedAt'] = pd.to_datetime(filings['filedAt'])  # Convert to datetime
        return filings
    except Exception as e:
        print(f"Error fetching filings: {e}") # Log the error for debugging
        return None



def get_stock_data(ticker, start_date, end_date):
    try:
        stock_data = yf.download(ticker, start=start_date, end=end_date)
        return stock_data
    except Exception as e:
        print(f"Error fetching stock data: {e}") # Log the error for debugging
        return None



def analyze_filing(filing, stock_data):
    # Placeholder for report analysis (Implement your logic here)
    # This is where you classify the report (great, fair, bad)
    # For now, just return a dummy classification
    return "fair"  # Replace with actual analysis


def calculate_returns_volatility(stock_data, announcement_date):
    try:
        pre_announcement_start = announcement_date - datetime.timedelta(days=3)
        pre_announcement_end = announcement_date
        post_announcement_start = announcement_date + datetime.timedelta(days=1) # +1 to avoid including announcement day
        post_announcement_end = announcement_date + datetime.timedelta(days=3)

        pre_announcement_data = stock_data[pre_announcement_start:pre_announcement_end]
        post_announcement_data = stock_data[post_announcement_start:post_announcement_end]

        if pre_announcement_data.empty or post_announcement_data.empty:
            return None  # Handle cases where data is missing

        pre_returns = pre_announcement_data['Close'].pct_change().dropna()
        post_returns = post_announcement_data['Close'].pct_change().dropna()

        avg_return = pd.concat([pre_returns, post_returns]).mean()

        volatility = pd.concat([pre_returns, post_returns]).std()

        return avg_return.item(), volatility.item() #.item() to convert numpy float to standard python float

    except Exception as e:
        print(f"Error calculating returns/volatility: {e}")
        return None



def process_filing(ticker, filing):
    filing_date = filing['filedAt'].to_pydatetime()
    stock_data = get_stock_data(ticker, filing_date - datetime.timedelta(days=7), filing_date + datetime.timedelta(days=7)) # Get 7 days before and after

    if stock_data is None or stock_data.empty:
      return None

    classification = analyze_filing(filing, stock_data)
    returns_volatility = calculate_returns_volatility(stock_data, filing_date)

    if returns_volatility is None:
        return None

    avg_return, volatility = returns_volatility
    return {
        "filing_date": filing_date,
        "classification": classification,
        "return": avg_return,
        "volatility": volatility,
    }

def format_data(ticker, filings_data):
    formatted_data = {"Query": ticker, "Years": []}
    for year, year_filings in filings_data.groupby(filings_data['filedAt'].dt.year):
        year_data = {year: []}
        for quarter, quarter_filings in year_filings.groupby(filings_data['filedAt'].dt.quarter):
            quarter_data = {"Quarterly": []}
            for index, filing in quarter_filings.iterrows():
                processed_filing = process_filing(ticker, filing)
                if processed_filing:
                    quarter_data["Quarterly"].append({f"Q{quarter}": processed_filing})
            year_data[year].append(quarter_data)

        formatted_data["Years"].append(year_data)
    return formatted_data


@app.route('/api/data/<ticker>')
def get_data(ticker):
    try:
        filings_data = get_filings_data(ticker)
        if filings_data is None or filings_data.empty:
            return jsonify({"message": "No data found for this ticker"}), 404

        formatted_data = format_data(ticker, filings_data)

        # Store data in MongoDB
        # result = collection.insert_one(formatted_data) # Only insert if you want to store everything
        # print(f"Inserted document ID: {result.inserted_id}")

        return jsonify(formatted_data), 200

    except Exception as e:
        print(f"API Error: {e}") # Log the error
        return jsonify({"error": "An error occurred"}), 500


if __name__ == '__main__':
    import os
    port = int(os.environ.get("PORT", 5000))  # Get port from environment variable
    app.run(debug=True, host='0.0.0.0', port=port) # host 0.0.0.0 makes the app available to the network. Very important for deployment